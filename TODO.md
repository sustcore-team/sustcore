# EMERGENCY

## 1. cap_degrade() 函数(SOLVED)

提供一个Capability降级函数, cap_degrade(), 让进程主动降级自己的Capbility权限, 使得以下操作可以实现:

1. fork() 一个新进程
2. 通过 cap_degrade() 主动降级自身的Capability
3. 通过 exec() 执行新程序, 使得新程序拥有受限的Capability

## 2. fork() 调用时的单线程检测与能力继承(SOLVED)

在执行fork()时, 检测当前进程是否为单线程进程, 如果不是, 则返回错误码, 防止多线程进程调用fork()导致的不确定行为.
同时, fork()调用将会克隆当前进程的所有能力, 并将其传递给新创建的子进程, 并保持其位置不变.
需要注意的是, 子进程的PCB能力并不遵循这一点: 此时, 子进程将会获得一个新的PCB能力, 其指向子进程的PCB结构体, 而父进程将得到该能力的一个克隆.

## 3. Capability管理系统

对于每一类Capability, 其都应当实现一个管理系统. 该管理系统的职权为:

1. 管理Capability指向的内核对象(如PCB, 内存页, Notification, 等等). 当没有Capability指向一个内核对象时, 该对象应当被销毁以释放资源.
2. 通过Capability对这些内核对象进行访问控制. 其应当在创建一个内核对象时及时返回一个全权限的Capability, 并允许通过该Capability派生出新的Capability,
允许Capability的降级操作, 并阻止Capability的升级操作.
3. 管理所有的Capability权限与Capability自身. 也就是说, 所有的Capability权限都由该管理系统管理, 内核的其余部分无论如何都不应该直接操作Capability权限.
4. 提供接口函数, 允许进程通过Capability对内核对象进行操作.
5. 与slab分配器协同工作, 以高效地分配和回收Capability对象.

> 由于该系统尚未实现, 因此目前内核中对Capability的管理仍然是分散的, 各个模块自行管理各自的Capability. 对Capability的遍历等功能其实现也较为困难.
> 而Notification与Memory能力目前的实现也会引起内存泄漏. 进程的销毁工作也不便进行.
> 因此将该待办项列提升为EMERGENCY级别.

在该系统完成后, 还应实现

### 3.1 对Capability的统一操作接口与遍历接口

提供统一的接口函数, 允许进程通过Capability对内核对象进行操作. 这些接口函数应当接受一个Capability指针作为参数, 并根据Capability的类型调用对应的管理系统进行处理.
同时, 提供接口函数, 允许内核遍历所有的Capability对象, 以便进行调试和管理.

### 3.2 Capability的审计与日志记录

提供审计功能, 记录对Capability对象的所有操作. 从而帮助系统调试.

### 3.3 进程销毁操作的实现

实现进程的销毁操作, 包括释放进程所拥有的所有Capability对象.

### 3.4 命名Capability的实现

允许进程在创建或派生某些Capability对象进行命名, 以便其他进程通过名称访问这些Capability对象.
例如, 进程A创建了一个Notification能力. 在这之后, 它将该能力派生到进程B中, 并命名为"notif1".
那么, 进程B就可以通过名称"notif1"来获得该能力的Capability指针.

## 4. 实现内存能力, 支持对内存页的能力管理

实现内存能力(Memory Capability), 允许进程通过内存能力对内存页进行访问和管理.

## 5. 实现基础的IPC机制, 允许进程间进行通信和数据交换.

RT.

## 6. 实现基础的RPC机制, 允许进程进行远程过程调用.

由于系统是微内核, 系统调用的实现主要依赖于RPC接口(Remote Procedure Call). RPC接口的过程为:

1. 进程通过陷入内核态, 触发系统调用
2. 内核通过RPC机制将系统调用请求发送到对应的服务进程
3. 服务进程处理请求, 并将结果通过RPC机制返回给内核
4. 内核将结果返回给用户进程

进一步的, 我们将其优化为以下机制:

1. 每个RPC提供者同时注册多个待命线程, 每个线程独立处理RPC请求
2. 当内核接收到RPC请求时, 选择一个空闲线程处理该请求
3. 线程处理完请求后, 将结果返回给内核, 并继续等待下一个请求
4. 当没有可用线程时, 内核将请求排队, 待有线程空闲时再处理

进一步的, 一个RPC过程可以是同步的.
对于同步RPC过程, 每次调度调用者线程时,
调用过程会被重定向到被调用者线程上.

## 7. 设计并实现基于能力的基础驱动模型, 并通过RPC机制来允许进程访问硬件设备.

RT.

## 8. 实现基础的文件系统接口, 允许进程进行文件操作.

RT.

## 9. 实现模拟硬件ramdisk设备及其驱动

ramdisk设备为一个模拟的块设备, 其存储空间完全驻留在内存中.
实现该设备的驱动程序, 允许进程通过文件系统接口对其进行读写操作.
特别地, 内核本身在启动时就会将附加于内核文件中的特殊只读ramdisk映像加载到内存中,
并通过附加于内核文件中的ramdisk驱动进行访问.
ramdisk映像包含了足以支持系统最小化运行的各种文件, 包括但不限于基本的硬盘驱动,
默认的shell程序, 基本的系统库等.
从而保证即使外部存储设备不可用, 系统仍然可以通过ramdisk进行基本的文件操作和程序执行.
并由此抢救系统.

ramdisk设备将是系统启动时第一个加载的硬盘类设备, 也是系统崩溃时最后一个可用的硬盘类设备.
如果系统已经正常启动, 当ramdisk设备发生故障时, 系统也可通过已经挂载的其他硬盘类设备继续运行,
并及时恢复ramdisk设备的功能.
而当其它硬盘类设备发生故障时, 系统仍然可以通过ramdisk设备保证一定程度上的文件操作和程序执行能力,
并逐渐恢复其它硬盘类设备的功能.

## 10. 实现virtio设备及其驱动

RT.

## 11. Loongarch架构支持

目前的内核主要支持RISC-V架构, 需要增加对Loongarch架构的支持.

## 12. 实现 cap_remove() 函数

提供一个Capability移除函数, cap_remove(), 允许进程主动移除自己的Capability,使得该Capability不再有效, 并释放其占用的资源.

## 13. 实现VFS

# IMPORTANT

## 1. fast path机制

fastpath机制是一种优化RPC调用性能的技术. 通过该机制, 某些RPC调用可以绕过传统的上下文切换和调度开销, 从而显著提高RPC调用的效率. 该机制的实现细节如下:
首先, 一个支持fast path机制的RPC过程总是同步的:

1. 对于某些RPC功能, 其被注册为支持fast path机制
2. 提供者应当保证, 当线程进入等待状态时, 支持fast path机制的RPC完全不依赖于任何的局部上下文信息(寄存器, 栈等)
3. 当内核接收到fast path RPC请求时, 直接将请求发送到空闲线程, 无需保存和恢复任何上下文信息, 此时的参数直接存储在线程的上下文中(寄存器等)
4. 线程处理完请求后, 直接返回结果给内核, 无需恢复任何上下文信息

## 2. COW(Copy-On-Write)机制的实现

在 fork() 中实现COW机制, 以提高内存使用效率和进程创建性能.

## 4. 将线程栈由内核分配改为用户态分配

线程栈的分配方式由内核分配改为用户态分配. 具体而言, 在创建线程时, 由用户态程序提供线程栈的起始地址和大小,
内核仅负责记录该信息并在调度线程时切换栈指针. 这样可以减少内核态的内存分配开销, 并允许用户态程序更灵活地管理线程栈的内存.

## 5. 实现对sh脚本的解析

实现一个简单的sh脚本解析器, 允许用户编写和执行sh脚本. 该解析器应当支持基本的sh语法和命令, 包括变量赋值, 条件语句, 循环语句等.

## 6. 实现一个简单的交互式shell

实现一个简单的交互式shell, 允许用户在命令行界面下输入和执行命令. 该shell应当支持基本的命令解析和执行功能, 包括内置命令和外部命令的执行.

## 7. 实现slab()

是的, 我应当实现它, 但是我太懒了.

## 8. 利用Capability对CSlot进行控制

每个PCB中都含有一个CSpace数组, 其中存放着若干个CSpace. CSpace的实质是一个CSlot(Capability *)数组, 每个CSlot实质上都是一个Capability指针.
进程通过指定CSpace索引和CSlot索引来访问其Capability对象. 这两个索引被统一到一个64位整数中, 其中高32位为CSpace索引, 低32位为CSlot索引.
目前, 为进程创建能力时, CSlot由内核主动寻找空闲位置进行分配. 但是, 这并不安全, 因为进程无法控制其CSlot的分配和使用情况.
例如, 一个恶意进程可以大量向另一个进程派生能力, 导致该进程的CSlot被耗尽, 从而无法创建新的能力.
为了解决这个问题, 我们应当利用Capability对CSlot进行控制.
具体而言, 我们应当把寻找CSlot与派生Capability的操作分开.
而对CSlot的使用也通过Capability系统进行控制.
具体而言, 我们可以实现一个CSpaceCapability. 虽然CSpace是PCB的一部分,
但我们确实应当将其从PCB中分离出来, 使得其成为一个独立的内核对象. 不过, 获取CSpaceCapability的唯一途径是通过PCBCapability.
CSpaceCapability允许进程对其CSlot进行分配和释放操作. 其存储有一个位图, 用于记录CSlot的使用情况.
当进程需要创建一个新的Capability时, 其首先通过PCBCapability获取其CSpaceCapability, 然后通过CSpaceCapability分配一个新的CSlot.
当进程不再需要某个Capability时, 其通过CSpaceCapability释放该Capability对应的CSlot.
当进程需要向某个进程派生Capability时, 其应当遵守以下步骤:

1. 通过系统调用进行不带CapPtr的派生. 该请求将被保存在内核中, 并分配一个独特的Request ID, 并等待目标进程处理.
2. 通过某种方式将Request ID发送给目标进程. 接下来目标进程有多种选择:
    - 拒绝该请求, 使得该请求失效.
    - 接受该请求, 并委托系统调用为其分配一个新的CSlot用于存放该Capability. 系统将在稍后将CapPtr传递给目标进程.
    - 接受该请求, 并向系统传递一个有效的CapPtr.

如果进程间需要频繁地派生Capability, 则可以预先将CSpaceCapability派生给目标进程, 使得目标进程可以通过CSpaceCapability自行分配CSlot.

# OPTIMIZATIONS

## 1. printf系列函数的改进

现有的 printf 函数采取的处理流程如下:

1. 在栈中预留一个固定大小的缓冲区, 用于存放格式化后的字符串
2. 通过 _llprintf 函数将格式化后的字符串写入该缓冲区
3. 通过指定的输出函数将缓冲区中的字符串输出

该实现存在的问题为, 当格式化的字符串过长时, 会导致缓冲区溢出.
应当对该实现进行改进, 使得在缓冲区用尽时, 及时输出当前缓冲区内容, 并继续格式化剩余内容.

## 2. Logger 系统改进

将内核不同部分(内存, 进程, 系统调用...)的日志输出进行分类. 具体而言, 通过一个结构体
来存放不同部分的日志输出信息(日志名, 输出函数, 启用情况等), 并提供接口函数用于注册和使用这些日志输出信息.
同时应该避免函数指针的使用.

## 3. ID分配器的改进

利用宏实现一个通用的ID分配器, 允许不同类型的ID使用同一套分配和回收逻辑.
从而简化TID, PID, CAPID等ID的分配器实现.

## 4. SV48 页表的实现

参照已有的 SV39 页表实现, 实现 SV48 页表的相关功能, 包括页表项的定义, 地址转换等.

## 5. 进程调度算法的优化

将进程调度队列分为以下三级

1. 实时队列: 用于存放实时进程, 采用先到先服务(FCFS)调度算法.
2. 普通队列: 用于存放普通进程, 采用时间片轮转(RR)调度算法.
3. 批处理队列: 用于存放批处理进程, 采用多级反馈队列(MFQ)调度算法.
4. 空闲队列: 用于存放空闲进程, 仅在系统无其他可运行进程时调度.

调度器总是优先调度实时队列, 其次是普通队列, 然后是批处理队列, 最后是空闲队列.
普通队列中, 进程时间片的数量由如下方式确定:

1. 首先, 系统分配给 init 进程一定的时间片数量.
2. 若进程 A 拥有 $N$ 个总时间片, 优先级为 $P$, 其子进程为 $B_1, B_2, \cdots , B_M$, 优先级为 $P_1, P_2, \cdots, P_M$,
   则总优先级为 $P_{\text{total}} = P + \sum_{i=1}^{M} P_i$, 则进程 A 的时间片数量为 $N \times \frac{P}{P_{\text{total}}}$, 每个子进程 $B_i$ 的时间片数量为 $N \times \frac{P_i}{P_{\text{total}}}$, 即按优先级比例分配时间片数量.
3. 若进程在其时间片用尽前主动放弃 CPU, 则其未用完的时间片将保留到其下一次调度.

## 6. EBPF支持

内核应当支持EBPF(Extended Berkeley Packet Filter)功能, 允许用户态程序加载和执行EBPF程序, 以实现高效的网络数据包处理和其他内核级功能扩展.
对于Verifier部分, 我们应当先实现一个基础的EBPF指令集验证器, 确保加载的EBPF程序不会执行非法操作或访问越界内存.

## 7. ELF加载器的改进

目前的ELF加载器实现较为简单, 仅支持基本的ELF格式和加载方式. 需要对其进行改进, 以支持更多的ELF特性和加载方式, 包括但不限于:
1. 支持动态链接库的加载和链接
2. 支持更多的ELF节类型和段类型

## 8. 优化线程等待队列的实现

RT

## 9. 实现基础的网络接口, 允许进程进行网络通信.

RT.

## 10. 实现简单的GUI系统.

RT.